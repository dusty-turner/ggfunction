---
title: "ggfunction: A Grammar of Graphics for Mathematical Functions and Probability Distributions"
abstract: >
  The \pkg{ggfunction} R package extends \CRANpkg{ggplot2} by providing a principled,
  unified interface for visualizing mathematical functions and probability distributions.
  It is organized around two complementary families. The first is a dimensional taxonomy
  classifying functions by their input and output dimensions: scalar functions
  $f\colon \mathbb{R} \to \mathbb{R}$, parametric curves
  $\boldsymbol{\gamma}\colon \mathbb{R} \to \mathbb{R}^2$, scalar fields
  $f\colon \mathbb{R}^2 \to \mathbb{R}$, and vector fields
  $\mathbf{F}\colon \mathbb{R}^2 \to \mathbb{R}^2$. The second family provides
  specialized geoms for probability distributions--density, cumulative distribution,
  mass, quantile, discrete cumulative distribution, discrete quantile, discrete survival,
  survival, and hazard functions--each with built-in support for
  region shading central to hypothesis testing and interval estimation. By embedding
  function evaluation, numerical integration, and validation directly into the
  \CRANpkg{ggplot2} layer system, \pkg{ggfunction} lets users move from a mathematical
  definition to a publication-quality visualization in a single, composable call.
author:
  - name: Dusty Turner
    affiliation: United States Military Academy
    address: West Point, NY
    email: dusty.s.turner@gmail.com
    orcid: 0000-0000-0000-0000
  - name: James Otto
    affiliation: Alcon Inc.
    address: Fort Worth, TX
    email: james.otto@alcon.com
  - name: Rodney X. Sturdivant
    affiliation: Baylor University
    address: Waco, TX
    email: rodney_sturdivant@baylor.edu
  - name: David Kahle
    affiliation: Baylor University
    address: Waco, TX
    email: david_kahle@baylor.edu
date: "2026-02-21"
date_received: ~
journal:
  firstpage: 1
  lastpage: ~
slug: turner-kahle-sturdivant-ggfunction
creative_commons: CC BY
packages:
  cran:
    - ggplot2
    - ggdist
    - mosaic
    - metR
    - rlang
    - cli
    - patchwork
    - lattice
  bioc: ~
  other:
    - ggfunction
    - ggvfields
CTV: ~
output:
  rjtools::rjournal_pdf_article:
    toc: no
  rjtools::rjournal_web_article:
    self_contained: yes
    toc: no
    includes:
      in_header: resources/mathjax_macros.html
    lua-filter: parse-fig-caption.lua
    dev: svg
bibliography: RJreferences.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.width = 6,
  fig.height = 3,
  fig.align = "center",
  out.width = "85%",
  warning = FALSE,
  message = FALSE
)

options(
  ggplot2.continuous.colour = NULL,
  ggplot2.continuous.fill = NULL
)
```

# Introduction

Visualizing mathematical functions is one of the most common tasks in applied mathematics and statistics--and one of the most under-supported in the grammar of graphics. Whether an instructor is shading a rejection region under a normal curve, a researcher is inspecting a scalar field over a spatial domain, or a student is tracing a parametric spiral, the need to move quickly from a function's definition to its graphical representation arises constantly. In R, \CRANpkg{ggplot2} [@wickham2010layered; @wickham2016ggplot2] has become the dominant visualization framework, yet its native support for plotting functions remains narrow. The built-in `stat_function()` evaluates a univariate function over a range and draws it as a path--perfectly adequate for $f\colon \mathbb{R} \to \mathbb{R}$, but offering nothing for parametric curves, scalar fields, vector fields, or the rich family of functions associated with probability distributions.

Several packages address pieces of this gap. \CRANpkg{ggdist} [@kay2024ggdist] provides sophisticated distribution visualizations oriented toward Bayesian uncertainty communication. \CRANpkg{mosaic} [@pruim2017mosaic] offers `plotDist()` for pedagogical work, but it is built on the \CRANpkg{lattice} [@lattice] framework rather than the grammar of graphics. \CRANpkg{metR} provides contour and vector-field displays for meteorological data, though it requires precomputed grids rather than function objects. None of these packages offers a unified treatment of functions organized by their dimensional structure.

\pkg{ggfunction} fills this gap by extending \CRANpkg{ggplot2} with a principled taxonomy of function types, classified by the dimensions of their domain and codomain. It provides two complementary families of geoms:

1. A **dimensional taxonomy** covering four function types: $\mathbb{R} \to \mathbb{R}$, $\mathbb{R} \to \mathbb{R}^2$, $\mathbb{R}^2 \to \mathbb{R}$, and $\mathbb{R}^2 \to \mathbb{R}^2$.
2. A **probability distribution family** providing specialized layers for density, cumulative distribution, mass, quantile, discrete cumulative distribution, discrete quantile, discrete survival, survival, and hazard functions.

Each layer follows the \CRANpkg{ggplot2} extension pattern: a `Stat` object evaluates the user-supplied function on a grid or sequence, and a corresponding `Geom` renders the result. Because every \pkg{ggfunction} layer is a standard \CRANpkg{ggplot2} layer, it composes freely with the full ecosystem of scales, coordinates, themes, and facets.

The remainder of this article is organized as follows. We describe the design principles underlying the package in Section 2. Sections 3 and 4 present the dimensional taxonomy and probability distribution family, respectively, illustrating each with examples. Section 5 addresses implementation details, Section 6 demonstrates composability with the broader grammar, Section 7 surveys related packages, and Section 8 concludes.

# Design principles

## A taxonomy grounded in dimension

The central organizing principle of \pkg{ggfunction} is that any function visualizable in two-dimensional space belongs to one of four classes, determined by the dimensions of its domain $m$ and codomain $n$:

\begin{equation}
\begin{aligned}
f &\colon \mathbb{R} \to \mathbb{R}        & \quad & (m = 1,\; n = 1) \\
\boldsymbol{\gamma} &\colon \mathbb{R} \to \mathbb{R}^2  & \quad & (m = 1,\; n = 2) \\
f &\colon \mathbb{R}^2 \to \mathbb{R}      & \quad & (m = 2,\; n = 1) \\
\mathbf{F} &\colon \mathbb{R}^2 \to \mathbb{R}^2 & \quad & (m = 2,\; n = 2)
\end{aligned}
(\#eq:taxonomy)
\end{equation}

Each class admits a natural visual encoding:

- **Scalar functions** ($\mathbb{R} \to \mathbb{R}$): curves in the Cartesian plane, optionally with region shading between the curve and the $x$-axis.
- **Parametric curves** ($\mathbb{R} \to \mathbb{R}^2$): directed paths with color encoding the time parameter.
- **Scalar fields** ($\mathbb{R}^2 \to \mathbb{R}$): raster heatmaps, contour lines colored by level value, or filled contour regions.
- **Vector fields** ($\mathbb{R}^2 \to \mathbb{R}^2$): short arrows at grid points (default) or streamlines computed by numerical integration of the field.

The naming convention--`geom_function_1d_1d()`, `geom_function_1d_2d()`, `geom_function_2d_1d()`, and `geom_function_2d_2d()`--encodes the dimensional signature directly, making the function's type explicit at the point of use.

## Integration with the grammar of graphics

The grammar of graphics [@wilkinson2005grammar] decomposes a graphic into orthogonal components: data, aesthetic mappings, geometric objects, statistical transformations, scales, coordinate systems, and facets. \CRANpkg{ggplot2} implements this decomposition through the `ggproto` object system, which allows new `Stat` and `Geom` classes to be defined and composed with existing infrastructure.

Every \pkg{ggfunction} layer follows this pattern. The user supplies a function object via the `fun` parameter and domain bounds via `xlim` and, where appropriate, `ylim`. The `Stat` evaluates the function on a suitable grid and returns a data frame whose columns correspond to the aesthetic variables expected by the `Geom`. Because the result is a standard \CRANpkg{ggplot2} layer, it composes with `+` alongside any other layer, scale, or theme.

A key design choice is the use of `rlang::inject()` to splice additional function arguments supplied through the `args` parameter. This allows users to parameterize functions without closures or anonymous wrappers:

```{r, eval=FALSE, echo=TRUE}
# instead of wrapping in an anonymous function:
ggplot() + geom_pdf(fun = function(x) dnorm(x, mean = 5, sd = 2), xlim = c(0, 10))

# users can write:
ggplot() + geom_pdf(fun = dnorm, xlim = c(0, 10), args = list(mean = 5, sd = 2))
```

This pattern is consistent across all \pkg{ggfunction} layers and mirrors the `args` parameter already familiar from `ggplot2::stat_function()`.

# The dimensional taxonomy

## Scalar functions: $\mathbb{R} \to \mathbb{R}$ {#sec-1d-1d}

The simplest case is a univariate function rendered as a curve in the plane. `geom_function_1d_1d()` generalizes `ggplot2::stat_function()` by adding support for region shading. The function is evaluated at $n$ equally-spaced points (default $n = 101$) over the specified `xlim`, and the resulting $(x, y)$ pairs are drawn as a path.

```{r sin-curve, echo=TRUE}
#| fig.cap: "The sine function over one full period."
library("ggfunction")

ggplot() +
  geom_function_1d_1d(fun = sin, xlim = c(0, 2 * pi))
```

The `shade_from` and `shade_to` parameters fill the region between the curve and the $x$-axis over a specified interval $[a, b]$. Boundary values are computed by linear interpolation via `stats::approxfun()`, so the shaded region aligns precisely with the requested interval even when $a$ or $b$ fall between evaluation points.

```{r shaded-cosine, echo=TRUE}
#| fig.cap: "The cosine function over $[0, 2\\pi]$ with the interval $[0, \\pi/2]$ shaded; the shaded area equals $\\int_0^{\\pi/2} \\cos(x)\\,dx = 1$."
ggplot() +
  geom_function_1d_1d(
    fun = cos, xlim = c(0, 2 * pi),
    shade_from = 0, shade_to = pi / 2
  )
```

## Parametric curves: $\mathbb{R} \to \mathbb{R}^2$ {#sec-parametric}

A parametric curve $\boldsymbol{\gamma}(t) = (x(t),\, y(t))$ maps a scalar parameter--typically time--to a trajectory in the plane. `geom_function_1d_2d()` evaluates the user-supplied function over the range specified by `tlim` with step size `dt`, producing columns `t`, `x`, and `y`. By default, color is mapped to `after_stat(t)` to encode progression along the curve.

```{r spiral, echo=TRUE}
#| fig.cap: "A parametric spiral $\\boldsymbol{\\gamma}(t) = (\\sin t,\\; t\\cos t)$ for $t \\in [0, 20]$, with color encoding the time parameter."
f_spiral <- function(t) c(sin(t), t * cos(t))

ggplot() +
  geom_function_1d_2d(fun = f_spiral, tlim = c(0, 20), tail_point = TRUE)
```

The `tail_point` parameter adds a marker at the starting position, useful for indicating an initial condition. The `args` parameter supports parameterized curve families. Lissajous figures $\boldsymbol{\gamma}(t) = (A\sin(at + \delta),\; B\sin(bt))$, for example, can be explored by varying frequency and phase:

```{r lissajous, echo=TRUE}
#| fig.cap: "A Lissajous figure with frequency ratio $a/b = 3/2$ and phase offset $\\delta = \\pi/2$."
lissajous <- function(t, A = 1, B = 1, a = 3, b = 2, delta = pi/2) {
  c(A * sin(a * t + delta), B * sin(b * t))
}

ggplot() +
  geom_function_1d_2d(
    fun = lissajous, tlim = c(0, 2 * pi),
    args = list(A = 1, B = 1, a = 3, b = 2, delta = pi/2)
  )
```

## Scalar fields: $\mathbb{R}^2 \to \mathbb{R}$ {#sec-scalar-fields}

A scalar field assigns a real value to each point in a two-dimensional domain. `geom_function_2d_1d()` evaluates the user-supplied function on a regular $n \times n$ grid (default $n = 50$) over `xlim` $\times$ `ylim`. The function must accept a numeric vector of length two and return a scalar; internally, a helper applies it row-wise over the grid. Three visualization modes are available through the `type` argument:

- `"raster"` (default): a heatmap with fill mapped to `after_stat(z)`.
- `"contour"`: iso-level curves with `colour` mapped to `after_stat(level)`, producing a colored legend automatically.
- `"contour_filled"`: filled regions between contour levels rendered by `ggplot2::GeomContourFilled`.

```{r gaussian-raster, echo=TRUE}
#| fig.cap: "A Gaussian bump $f(x, y) = \\exp(-(x^2 + y^2)/2)$ rendered as a raster heatmap."
f_gaussian <- function(u) {
  x <- u[1]; y <- u[2]
  exp(-(x^2 + y^2) / 2)
}

ggplot() +
  geom_function_2d_1d(fun = f_gaussian, xlim = c(-3, 3), ylim = c(-3, 3))
```

The contour modes are selected simply by changing `type`:

```{r gaussian-contour, echo=TRUE, fig.width=10, fig.height=3}
#| fig.cap: "The same Gaussian bump rendered as contour lines (left) and filled contours (right)."
p_contour <- ggplot() +
  geom_function_2d_1d(
    fun = f_gaussian, xlim = c(-3, 3), ylim = c(-3, 3), type = "contour"
  ) + ggtitle("type = \"contour\"")

p_filled <- ggplot() +
  geom_function_2d_1d(
    fun = f_gaussian, xlim = c(-3, 3), ylim = c(-3, 3), type = "contour_filled"
  ) + ggtitle("type = \"contour_filled\"")

library("patchwork")

p_contour | p_filled
```

For the contour variants, the `StatFunction2dContour` and `StatFunction2dContourFilled` classes extend the corresponding \CRANpkg{ggplot2} stats. The `setup_params()` method pre-computes the function grid so that `z.range` is available for automatic break computation before any data is rendered.

## Vector fields: $\mathbb{R}^2 \to \mathbb{R}^2$ {#sec-vector-fields}

A vector field $\mathbf{F}(x, y) = (F_1(x, y),\; F_2(x, y))$ assigns a direction and magnitude to each point in the plane. `geom_function_2d_2d()` delegates to \pkg{ggvfields} [@ggvfields] and supports two display modes through the `type` argument.

**Vector arrows (default).** With `type = "vector"` (the default), short arrows are drawn at each grid point, oriented according to the field direction and scaled relative to the grid spacing.

```{r rotation-field, echo=TRUE}
#| fig.cap: "The rotation field $\\mathbf{F}(x, y) = (-y, x)$ displayed as short arrows at each grid point."
f_rotation <- function(u) {
  x <- u[1]; y <- u[2]
  c(-y, x)
}

ggplot() +
  geom_function_2d_2d(fun = f_rotation, xlim = c(-1, 1), ylim = c(-1, 1))
```

**Streamlines.** With `type = "stream"`, integral curves are computed by numerical integration of the field using a fourth-order Runge--Kutta method [@ggvfields] and rendered as directed paths seeded on a regular grid.

```{r rotation-stream, echo=TRUE}
#| fig.cap: "The same rotation field rendered as streamlines, each following the counterclockwise flow induced by the field."
ggplot() +
  geom_function_2d_2d(fun = f_rotation, xlim = c(-1, 1), ylim = c(-1, 1),
    type = "stream")
```

Users whose primary interest is vector fields will find that \pkg{ggvfields} provides a richer collection of tools, including gradient fields, stream plots, and potential functions.

# The probability distribution family

Statistics education depends heavily on the visual language of probability distributions. Instructors shade tail areas to illustrate $p$-values, draw CDFs to connect probabilities with quantiles, and mark central regions to delineate confidence intervals. \pkg{ggfunction} provides a family of nine geoms that map directly onto the standard functions associated with a probability distribution, each with built-in shading support. Throughout, the user supplies an R function (e.g., `dnorm`, `pnorm`, `qnorm`) and a range; \pkg{ggfunction} handles evaluation, shading, and validation automatically.

## Density functions: `geom_pdf()`

The probability density function (PDF) of a continuous random variable $X$ satisfies

\begin{equation}
f(x) \geq 0 \quad \text{and} \quad \int_{-\infty}^{\infty} f(x)\, dx = 1.
(\#eq:pdf)
\end{equation}

`geom_pdf()` evaluates a user-supplied density and renders it as a filled area with an overlaid outline. The underlying `StatPDF` validates the normalization property \@ref(eq:pdf) using `stats::integrate()`, issuing a diagnostic via \CRANpkg{cli} [@cli] if the integral departs from unity by more than a specified tolerance--a guard against accidentally passing an unnormalized function.

Four shading modes are supported, corresponding to common pedagogical operations.

**Single threshold.** The `p` parameter specifies a cumulative probability. When `lower.tail = TRUE` (the default), the region from the left boundary to the $p$-quantile is shaded, representing $P(X \leq x_p) = p$. Setting `lower.tail = FALSE` shades the complementary upper tail.

**Two-sided interval.** The `p_lower` and `p_upper` parameters define a central region--the natural representation for a $(1 - \alpha)$ confidence interval.

**Tail shading.** Setting `shade_outside = TRUE` inverts the two-sided region, shading both tails. This directly represents the rejection region of a two-sided hypothesis test at level $\alpha$.

```{r pdf-shading-modes, echo=TRUE, fig.width=10, fig.height=3}
#| fig.cap: "Three shading modes for \\texttt{geom\\_pdf()}: lower tail ($p = 0.975$, left), central 95\\% interval (center), and two-tailed rejection region at $\\alpha = 0.05$ (right)."
p1 <- ggplot() +
  geom_pdf(fun = dnorm, xlim = c(-3, 3), p = 0.975) +
  ggtitle("p = 0.975")

p2 <- ggplot() +
  geom_pdf(
    fun = dnorm, xlim = c(-3, 3),
    p_lower = 0.025, p_upper = 0.975
  ) + ggtitle("Central 95%")

p3 <- ggplot() +
  geom_pdf(
    fun = dnorm, xlim = c(-3, 3),
    p_lower = 0.025, p_upper = 0.975, shade_outside = TRUE
  ) + ggtitle("\u03b1 = 0.05 rejection region")

p1 | p2 | p3
```

**Highest density region.** The `shade_hdr` parameter specifies a coverage probability and shades the corresponding highest density region (HDR)--the smallest subset of the domain containing the specified probability mass. For multimodal densities the HDR may be disconnected, producing multiple disjoint shaded intervals. The algorithm follows @otto2023ggdensity: evaluate the density on the grid, normalize the values to sum to one, sort in descending order, accumulate until the target coverage is reached, and shade all grid intervals at or above the resulting density threshold.

```{r pdf-hdr, echo=TRUE}
#| fig.cap: "The 80\\% highest density region of an asymmetric bimodal density ($0.6\\,\\mathcal{N}(-2,\\,0.6^2) + 0.4\\,\\mathcal{N}(2,\\,1.2^2)$), shading both modes as two disjoint intervals with more area allocated to the taller, narrower component."
f_mix <- function(x) 0.6 * dnorm(x, mean = -2, sd = 0.6) + 0.4 * dnorm(x, mean = 2, sd = 1.2)
ggplot() +
  geom_pdf(fun = f_mix, xlim = c(-5, 6), shade_hdr = 0.8)
```

The shading boundaries for the interval-based modes are determined by trapezoidal accumulation. For $n$ evaluation points $x_1, \ldots, x_n$ with density values $y_1, \ldots, y_n$, the cumulative area at the $k$-th point is

\begin{equation}
A_k = \sum_{i=1}^{k-1} \frac{y_i + y_{i+1}}{2} \, (x_{i+1} - x_i).
(\#eq:trapezoid)
\end{equation}

The normalized values $A_k / A_n$ are then compared against the specified probability thresholds to determine the shading boundaries.

## Probability mass functions: `geom_pmf()`

For a discrete random variable with integer support, the PMF $p(k) = P(X = k)$ satisfies $\sum_k p(k) = 1$. `geom_pmf()` evaluates the PMF at each integer in `xlim` and renders the result as a lollipop chart--vertical segments from the $x$-axis to the probability value, capped with points. The underlying `StatPMF` validates normalization by summing the computed probabilities and issues a warning if they depart significantly from unity. When the support is not a sequence of consecutive integers, the `support` argument accepts an explicit numeric vector that overrides `xlim`.

```{r pmf-binomial, echo=TRUE}
#| fig.cap: "The PMF of a $\\mathrm{Binomial}(10, 0.3)$ distribution, rendered as a lollipop chart."
ggplot() +
  geom_pmf(fun = dbinom, xlim = c(0, 10), args = list(size = 10, prob = 0.3))
```

The `support` argument enables distributions whose mass points are not consecutive integers. Figure~\ref{fig:pmf-clt} illustrates this with the exact distribution of the sample mean $\bar X_n = n^{-1}\sum_{i=1}^n X_i$ of $n = 10$ i.i.d.\ $\mathrm{Bernoulli}(0.3)$ draws. The support is $\{0, 0.1, 0.2, \ldots, 1\}$ and $P(\bar X_n = k/n) = \binom{n}{k}0.3^k 0.7^{n-k}$. The Central Limit Theorem approximation $\bar X_n \approx \mathcal{N}(0.3,\, 0.3 \times 0.7 / 10)$ is overlaid as a scaled density curve whose peak matches the tallest lollipop, facilitating direct visual comparison of shape without a secondary axis.

```{r pmf-clt, echo=TRUE}
#| fig.cap: "Exact distribution of the sample mean of 10 i.i.d.~Bernoulli(0.3) draws (lollipops) with the CLT normal approximation overlaid as a scaled density curve."
p <- 0.3; n <- 10
sd_mean <- sqrt(p * (1 - p) / n)
f_mean  <- function(x) dbinom(round(x * n), size = n, prob = p)
max_pmf <- max(f_mean(seq(0, 1, by = 1/n)))
scale   <- max_pmf / dnorm(p, mean = p, sd = sd_mean)
f_clt   <- function(x) scale * dnorm(x, mean = p, sd = sd_mean)

ggplot() +
  geom_pmf(fun = f_mean, support = seq(0, 1, by = 1/n)) +
  geom_pdf(fun = f_clt, xlim = c(0, 1))
```

`geom_pmf()` supports the same shading modes as `geom_pdf()`. The `p` parameter shades lollipops up to the $p$-quantile; `p_lower` and `p_upper` define a two-sided interval; `shade_outside = TRUE` inverts it; and `shade_hdr` shades the smallest set of mass points whose total probability meets or exceeds the target coverage. Unshaded lollipops are rendered in grey to preserve the distributional context. Because a discrete distribution may not achieve the exact target coverage, `shade_hdr` finds the smallest HDR with coverage $\geq$ the requested level and issues a diagnostic via \CRANpkg{cli} when the actual coverage differs from the target by more than 0.5 percentage points.

```{r pmf-shading, echo=TRUE}
#| fig.cap: "Shading modes for \\texttt{geom\\_pmf()}: the lower 80\\% by cumulative probability (left) and the 80\\% HDR of a $\\mathrm{Binomial}(10, 0.3)$ distribution (right). Unshaded lollipops are shown in grey."
p1 <- ggplot() +
  geom_pmf(fun = dbinom, xlim = c(0, 10),
    args = list(size = 10, prob = 0.5), p = 0.8) +
  ggtitle("p = 0.8")

p2 <- ggplot() +
  geom_pmf(fun = dbinom, xlim = c(0, 10),
    args = list(size = 10, prob = 0.3), shade_hdr = 0.8) +
  ggtitle("shade_hdr = 0.8")

p1 | p2
```

## Cumulative distribution and survival functions

The CDF $F(x) = P(X \leq x)$ and survival function $S(x) = 1 - F(x) = P(X > x)$ are complementary summaries of a distribution. \pkg{ggfunction} provides continuous and discrete variants of both.

**Continuous CDF (`geom_cdf()`).** `geom_cdf()` evaluates a user-supplied CDF (e.g., `pnorm`) and renders it as a line. It supports the same `p`, `p_lower`/`p_upper`, and `shade_outside` shading parameters as `geom_pdf()`.

```{r cdf-shaded, echo=TRUE}
#| fig.cap: "The standard normal CDF."
ggplot() +
  geom_cdf(fun = pnorm, xlim = c(-3, 3))
```

**Discrete CDF (`geom_cdf_discrete()`).** For discrete distributions, the CDF is a right-continuous step function. `geom_cdf_discrete()` takes a PMF, computes cumulative sums, and renders the result with horizontal segments, dashed vertical jumps, open circles at the pre-jump value (the left limit), and closed circles at the achieved value. The `show_points` and `show_vert` parameters independently suppress the endpoint circles or vertical jump segments. The `support` argument accepts an explicit numeric vector of mass points, overriding `xlim` for distributions with non-integer or non-consecutive support.

```{r discrete-cdf, echo=TRUE}
#| fig.cap: "The discrete CDF of a $\\mathrm{Binomial}(10, 0.5)$ distribution."
ggplot() +
  geom_cdf_discrete(
    fun = dbinom, xlim = c(0, 10), args = list(size = 10, prob = 0.5)
  )
```

**Continuous survival (`geom_survival()`).** In reliability theory and biostatistics, $S(x) = 1 - F(x) = P(X > x)$ gives the probability that the event of interest has not yet occurred by time $x$. `geom_survival()` accepts a CDF and plots its complement.

```{r survival-exp, echo=TRUE}
#| fig.cap: "The survival function of an $\\mathrm{Exponential}(0.5)$ distribution, $S(x) = e^{-0.5x}$."
ggplot() +
  geom_survival(fun = pexp, xlim = c(0, 10), args = list(rate = 0.5))
```

**Discrete survival (`geom_survival_discrete()`).** For discrete distributions, $S(x) = 1 - F(x)$ is itself a right-continuous step function. `geom_survival_discrete()` computes $S$ from a PMF and renders it with the same visual conventions as `geom_cdf_discrete()`. The `support` argument behaves as in `geom_cdf_discrete()`.

```{r discrete-survival, echo=TRUE}
#| fig.cap: "The discrete survival function of a $\\mathrm{Binomial}(10, 0.5)$ distribution, descending from 1 to 0."
ggplot() +
  geom_survival_discrete(
    fun = dbinom, xlim = c(0, 10), args = list(size = 10, prob = 0.5)
  )
```

## Quantile functions

The quantile function $Q(p) = \inf\{x : F(x) \geq p\}$ inverts the CDF. \pkg{ggfunction} provides continuous and discrete variants.

**Continuous (`geom_qf()`).** `geom_qf()` evaluates a user-supplied quantile function (e.g., `qnorm`) over the unit interval $(0, 1)$. Evaluation points are placed at Chebyshev nodes of the first kind, $p_k = (1 - \cos((2k-1)\pi / 2n))/2$ for $k = 1, \ldots, n$, which cluster near 0 and 1 where quantile functions are typically most curved and avoid evaluating at the exact endpoints, preventing $\pm\infty$ for unbounded distributions.

```{r qf-normal, echo=TRUE}
#| fig.cap: "The quantile function of the standard normal distribution."
ggplot() +
  geom_qf(fun = qnorm)
```

**Discrete (`geom_qf_discrete()`).** The quantile function of a discrete distribution is a left-continuous step function on $[0, 1]$. `geom_qf_discrete()` takes a PMF, computes the cumulative sum, and renders the inverse function with horizontal segments on $[0, 1]$, dashed vertical jumps, closed circles at the bottom of each jump (the value is achieved), and open circles at the top (the next value is not yet reached). The `support` argument behaves as in `geom_cdf_discrete()`.

```{r discrete-qf, echo=TRUE}
#| fig.cap: "The discrete quantile function of a $\\mathrm{Binomial}(10, 0.5)$ distribution as a left-continuous step function on $[0, 1]$."
ggplot() +
  geom_qf_discrete(
    fun = dbinom, xlim = c(0, 10), args = list(size = 10, prob = 0.5)
  )
```

## Hazard functions: `geom_hf()`

The hazard function

\begin{equation}
h(x) = \frac{f(x)}{S(x)} = \frac{f(x)}{1 - F(x)}
(\#eq:hazard)
\end{equation}

represents the instantaneous rate of failure at time $x$, conditional on survival to that point [@casella2002statistical]. `geom_hf()` requires both a PDF and a CDF, supplied via `pdf_fun` and `cdf_fun` respectively. The `args` parameter applies to both; `pdf_args` and `cdf_args` provide overrides where the two functions require different parameterizations.

Division by $S(x)$ can cause numerical instability in the tail as $S(x) \to 0$. `StatHF` guards against this by replacing values where $S(x) \leq 0$ with `NaN`, and `GeomHF` filters these before rendering.

Three canonical hazard shapes arise in reliability modeling: decreasing (infant mortality, where early failures dominate), constant (the memoryless Exponential distribution), and increasing (wear-out failure, where older units fail at higher rates).

```{r hazard-shapes, echo=TRUE, fig.width=10, fig.height=3}
#| fig.cap: "Three canonical hazard shapes: decreasing ($\\mathrm{Weibull}(\\mathrm{shape}{=}0.5,\\,\\mathrm{scale}{=}2)$, left), constant ($\\mathrm{Exponential}(0.5)$, center), and increasing ($\\mathcal{N}(0,1)$, right)."
p_decr <- ggplot() +
  geom_hf(
    pdf_fun = dweibull, cdf_fun = pweibull,
    xlim = c(0.01, 5), args = list(shape = 0.5, scale = 2)
  ) + ggtitle("Decreasing (Weibull)")

p_flat <- ggplot() +
  geom_hf(
    pdf_fun = dexp, cdf_fun = pexp,
    xlim = c(0.01, 10), args = list(rate = 0.5)
  ) + ggtitle("Flat (Exponential)")

p_incr <- ggplot() +
  geom_hf(
    pdf_fun = dnorm, cdf_fun = pnorm,
    xlim = c(-3, 3), args = list(mean = 0, sd = 1)
  ) + ggtitle("Increasing (Normal)")

p_decr | p_flat | p_incr
```

# Implementation

## Architecture

Each \pkg{ggfunction} layer is implemented as a pair of `ggproto` objects--a `Stat` and a `Geom`--wired together by a constructor function. The constructor creates a standard \CRANpkg{ggplot2} `layer()` call, threading the user-supplied function and its parameters through to the stat's `compute_group()` method. That method performs the core computation: evaluating the function on a grid or sequence and returning a data frame whose columns correspond to the aesthetic variables expected by the geom.

The separation of computation (stat) from rendering (geom) is not merely organizational. It allows users to substitute alternative geoms or compose multiple layers from the same stat. The `StatFunction2d` object, for instance, computes a grid of scalar-field values that can be rendered by `GeomRaster`, `GeomContour`, or `GeomContourFilled`, selected at construction time through the `type` parameter.

## Function injection

R's `...` mechanism does not compose well when a function is called inside a stat's `compute_group()` method, which must simultaneously receive \CRANpkg{ggplot2}-internal parameters. \pkg{ggfunction} adopts the approach used by `ggplot2::stat_function()`: additional arguments are collected in a named list (`args`) and injected at the call site via `rlang::inject()`:

```{r, eval=FALSE, echo=TRUE}
fun_injected <- function(x) {
  rlang::inject(fun(x, !!!args))
}
```

This pattern is simple, composable, and avoids the ambiguity of routing function arguments through `...`.

## Numerical considerations

Several layers involve numerical integration or accumulation:

- **PDF validation** uses `stats::integrate()` with adaptive quadrature to verify that the supplied function integrates to one over the specified domain.
- **Shading boundaries** are computed by trapezoidal accumulation \@ref(eq:trapezoid), which is efficient and sufficient for the smooth densities encountered in practice.
- **Boundary interpolation** in `GeomFunction1d` uses `stats::approxfun()` to compute exact $y$-values at shade endpoints that fall between evaluation points.
- **Quantile function evaluation** in `geom_qf()` uses Chebyshev nodes of the first kind rather than a uniform grid, concentrating evaluation points near $p = 0$ and $p = 1$ where the function is most curved and avoiding evaluation at the exact endpoints.
- **Vector field integration** (via \pkg{ggvfields}) uses a fourth-order Runge--Kutta method with configurable step size and maximum iterations.

The default resolution of $n = 101$ for one-dimensional functions and $n = 50$ for two-dimensional grids (yielding 2500 evaluation points) balances visual fidelity against computational cost. Users may increase $n$ for functions with fine-scale structure.

# Composability and the grammar

Because every \pkg{ggfunction} layer is a standard \CRANpkg{ggplot2} layer, it composes freely with the rest of the grammar. Layers can be overlaid, scaled, themed, annotated, and faceted exactly as one would with any other geom. The following example superimposes two normal densities with different means and spreads, demonstrating that function visualization and standard \CRANpkg{ggplot2} idioms are fully interoperable:

```{r composability, echo=TRUE}
#| fig.cap: "Two normal densities with different means and spreads overlaid in a single plot, demonstrating composability with the ggplot2 grammar of graphics."
ggplot() +
  geom_pdf(
    fun = dnorm, xlim = c(-5, 8),
    args = list(mean = 0, sd = 1), alpha = 0.4
  ) +
  geom_pdf(
    fun = dnorm, xlim = c(-5, 8),
    args = list(mean = 3, sd = 1.5), alpha = 0.4
  ) +
  labs(x = "x", y = "f(x)", title = "Comparing two normal densities") +
  theme_minimal()
```

This composability is the primary advantage of embedding function visualization within the grammar of graphics, rather than providing standalone plotting functions.

# Related packages {#sec:related}

Several existing packages overlap with \pkg{ggfunction} in purpose, and understanding their scope helps clarify where \pkg{ggfunction} fits.

1. \CRANpkg{ggplot2} [@wickham2016ggplot2]. The `stat_function()` layer handles scalar functions $\mathbb{R} \to \mathbb{R}$ competently, and `geom_function_1d_1d()` builds directly on this foundation. \CRANpkg{ggplot2} provides no analogues for parametric curves, scalar fields, vector fields, or probability-specific shading operations.

2. \CRANpkg{ggdist} [@kay2024ggdist]. This package excels at visualizing distributional uncertainty in Bayesian workflows: posterior distributions, predictive intervals, and uncertainty estimates from fitted models. Its geoms work primarily with samples or distributional objects rather than the `d`/`p`/`q`/`h` function families that \pkg{ggfunction} targets.

3. \CRANpkg{ggdensity} [@otto2023ggdensity]. This package improves bivariate density visualization in \CRANpkg{ggplot2}, with a particular focus on highest density regions (HDRs). \pkg{ggfunction}'s `shade_hdr` parameter in `geom_pdf()` follows the HDR computation approach introduced there: normalizing density values, sorting in descending order, and accumulating until the target coverage is reached.

4. \CRANpkg{mosaic} [@pruim2017mosaic]. The `plotDist()` function provides quick plots of named distributions and supports shading, but it is built on the \CRANpkg{lattice} [@lattice] graphics framework rather than \CRANpkg{ggplot2}, and therefore cannot be composed with \CRANpkg{ggplot2} layers.

5. \CRANpkg{metR} [@metR]. This package provides contour and vector-field geoms designed for meteorological data, requiring precomputed grids as inputs rather than function objects. Users who already have gridded data may find \CRANpkg{metR} more convenient; users who want to visualize a function directly will find \pkg{ggfunction} more natural.

6. \pkg{ggvfields} [@ggvfields]. \pkg{ggfunction}'s `geom_function_2d_2d()` delegates to \pkg{ggvfields} for streamline computation. For users whose primary interest is vector fields--including stream plots, gradient fields, and potential functions--\pkg{ggvfields} offers a substantially richer collection of tools built on the same \CRANpkg{ggplot2} extension architecture.

Taken together, these packages reflect the breadth of interest in function visualization within the R ecosystem. \pkg{ggfunction} is distinguished by its unified dimensional taxonomy and its integration of the full probability distribution function family--capabilities that, to our knowledge, no other single package provides within the grammar of graphics.

# Summary

\pkg{ggfunction} extends \CRANpkg{ggplot2} with a principled framework for visualizing mathematical functions and probability distributions. Its organizing taxonomy--classifying functions by the dimensions of their domain and codomain--yields a small, memorable API that covers the function types most commonly encountered in mathematics and statistics. The probability distribution family covers nine geoms spanning continuous and discrete distributions: density, CDF, PMF, quantile, discrete CDF, discrete quantile, discrete survival, survival, and hazard functions. Each supports the shading operations central to statistical pedagogy---marking quantiles, delineating confidence regions, highlighting rejection areas, and shading highest density regions.

By implementing each layer as a `ggproto` stat--geom pair, the package inherits the full composability of the grammar of graphics. Functions can be overlaid, themed, faceted, and annotated using the same tools that \CRANpkg{ggplot2} users already know. The `args` injection pattern provides a clean interface for parameterized function families, and built-in validation catches common errors--such as unnormalized densities--before they produce misleading graphics.

\pkg{ggfunction} is available at \url{https://github.com/dusty-turner/ggfunction} and can be installed via `pak::pak("dusty-turner/ggfunction")`.

# Acknowledgments

We thank the developers of \CRANpkg{ggplot2} for the extension system that makes packages like \pkg{ggfunction} possible.

```{r, echo=FALSE, results="asis"}
pkg_list <- c("ggplot2", "rlang", "cli")
for (pkg in pkg_list) {
  if (requireNamespace(pkg, quietly = TRUE)) invisible(NULL)
}
```
